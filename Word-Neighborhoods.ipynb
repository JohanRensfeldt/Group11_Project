{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43cc9d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      "org.mongodb#mongo-java-driver added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-ff9ef6f0-be2f-4162-a07f-4985de3808f0;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      "\tfound org.mongodb#mongo-java-driver;3.12.12 in central\n",
      ":: resolution report :: resolve 296ms :: artifacts dl 13ms\n",
      "\t:: modules in use:\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongo-java-driver;3.12.12 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-ff9ef6f0-be2f-4162-a07f-4985de3808f0\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 5 already retrieved (0kB/14ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/22 23:47:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "builder.\\\n",
    "appName(\"word-neighborhoods\").\\\n",
    "master(\"spark://spark-master:7077\").\\\n",
    "config(\"spark.worker.webui.port\", \"8081\").\\\n",
    "config(\"spark.executor.memory\", \"6g\").\\\n",
    "config(\"spark.executor.cores\", \"3\").\\\n",
    "config(\"spark.submit.deployMode\", \"client\"). \\\n",
    "config(\"spark.driver.bindAddress\", \"0.0.0.0\"). \\\n",
    "config(\"spark.mongodb.input.uri\",\"mongodb://admin:1989@mongoDb:27017/reddit.smallTest?authSource=admin\").\\\n",
    "config(\"spark.mongodb.output.uri\",\"mongodb://admin:1989@mongoDb:27017/reddit.smallTest?authSource=admin\").\\\n",
    "config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1,org.mongodb:mongo-java-driver:3.12.12\").\\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84bac7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/22 23:47:31 WARN MongoInferSchema: Field 'edited' contains conflicting types converting to StringType\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"mongo\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85258ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_id=Row(oid='641709530f263864b4918f66'), author='gmcg', author_flair_css_class=None, author_flair_text=None, body='THAN the title suggests.  Whoops.', controversiality=1, created_utc=1138752114, distinguished=None, edited='false', gilded=0, id='c166b', link_id='t3_15xh', parent_id='t3_15xh', retrieved_on=1473820870, score=0, stickied=False, subreddit='reddit.com', subreddit_id='t5_6', ups=0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2a1572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will keep only the column \"body\"\n",
    "df = df.drop('_id',\n",
    " 'author',\n",
    " 'author_flair_css_class',\n",
    " 'author_flair_richtext',\n",
    " 'author_flair_template_id',\n",
    " 'author_flair_text',\n",
    " 'author_flair_text_color',\n",
    " 'author_flair_type',\n",
    " 'author_fullname',\n",
    " 'author_patreon_flair',\n",
    " 'author_premium',\n",
    " 'can_gild',\n",
    " 'collapsed',\n",
    " 'collapsed_because_crowd_control',\n",
    " 'collapsed_reason',\n",
    " 'collapsed_reason_code',\n",
    " 'comment_type',\n",
    " 'controversiality',\n",
    " 'created_utc',\n",
    " 'distinguished',\n",
    " 'editable',\n",
    " 'edited',\n",
    " 'gilded',\n",
    " 'id',\n",
    " 'is_submitter',\n",
    " 'link_id',\n",
    " 'locked',\n",
    " 'media_metadata',\n",
    " 'name',\n",
    " 'no_follow',\n",
    " 'parent_id',\n",
    " 'permalink',\n",
    " 'retrieved_on',\n",
    " 'score',\n",
    " 'score_hidden',\n",
    " 'send_replies',\n",
    " 'stickied',\n",
    " 'subreddit',\n",
    " 'subreddit_id',\n",
    " 'subreddit_name_prefixed',\n",
    " 'subreddit_type',\n",
    " 'top_awarded_type',\n",
    " 'total_awards_received',\n",
    " 'unrepliable_reason')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = df.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7567ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(rc):\n",
    "    \n",
    "    text = rc.lower()\n",
    "    \n",
    "    import string\n",
    "    punc = string.punctuation #'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "    text = text.replace(\"\\r\", \" \")\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"'d\", \"\")\n",
    "    text = text.replace(\"'ll\", \"\")\n",
    "    text = text.replace(\"'m\", \"\")\n",
    "    text = text.replace(\"'re\", \"\")\n",
    "    text = text.replace(\"'s\", \"\")\n",
    "    text = text.replace(\"'ve\", \"\")\n",
    "    text = text.replace(\"n't\", \" not\")\n",
    "    text = text.replace(\"‘d\", \"\")\n",
    "    text = text.replace(\"‘ll\", \"\")\n",
    "    text = text.replace(\"‘m\", \"\")\n",
    "    text = text.replace(\"‘re\", \"\")\n",
    "    text = text.replace(\"‘s\", \"\")\n",
    "    text = text.replace(\"‘ve\", \"\")\n",
    "    text = text.replace(\"n‘t\", \" not\")\n",
    "    text = text.replace(\"’d\", \"\")\n",
    "    text = text.replace(\"’ll\", \"\")\n",
    "    text = text.replace(\"’m\", \"\")\n",
    "    text = text.replace(\"’re\", \"\")\n",
    "    text = text.replace(\"’s\", \"\")\n",
    "    text = text.replace(\"’ve\", \"\")\n",
    "    text = text.replace(\"n’t\", \" not\")\n",
    "    \n",
    "\n",
    "\n",
    "    for char in text:\n",
    "        if char in punc:\n",
    "            text = text.replace(char, \" \")\n",
    "\n",
    "\n",
    "    while \"  \" in text:\n",
    "\n",
    "        text = text.replace(\"  \", \" \")\n",
    "    \n",
    "    return(text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92727c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = rdd.map(lambda comm: preprocess(comm[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d445d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b33aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ec5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb8049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(rc):\n",
    "    \n",
    "    doc = rc.split()\n",
    "    \n",
    "    s = \"\"\n",
    "     \n",
    "    for x in doc:\n",
    "        \n",
    "        if not x in stopwords:\n",
    "            s = s + x + \" \"\n",
    "    \n",
    "    return(s.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c057beb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd3 = rdd2.map(lambda comm: remove_stopwords(comm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d424928",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd3.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6a093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(rc):\n",
    "    \n",
    "    doc = nlp(rc)\n",
    "    \n",
    "    return( str(doc[:].lemma_) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c533a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd4 = rdd3.map(lambda comm: lemmatize(comm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0722dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd5 = rdd4.map(lambda comm: comm.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e383a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "def mapper(rc):#rc: list\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    for x in permutations(rc,2):\n",
    "        l.append( (x,1) )\n",
    "    return(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a38cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x,y):\n",
    "    return(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3035d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd5_flat = rdd5.flatMap(lambda comm: mapper(comm)).reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb34515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### for example\n",
    "rdd5_flat.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6764c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = rdd5_flat.sortBy(lambda x: x[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d7597",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c550b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will also need the wordcounts of all the different single words.\n",
    "wc_rdd = rdd4.flatMap(lambda comm: comm.split() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71d35b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = wc_rdd.map(lambda word: (word, 1)).reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caec66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = word_counts.sortBy(lambda x: x[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad1e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the data bases for the matrix and the word counts\n",
    "base = matrix.toDF([\"words\", \"count\"]).selectExpr(\"words._1 as word1\", \"words._2 as word2\", \"count\")\n",
    "\n",
    "base.createOrReplaceTempView(\"mytable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eee5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcbase = spark.createDataFrame(word_counts, [\"word\", \"count\"])\n",
    "\n",
    "wcbase.createOrReplaceTempView(\"table2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d9fe6",
   "metadata": {},
   "source": [
    "##### Now we will choose different words and create for each word the 3 layers of related words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b4fd49e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# war\n",
    "\n",
    "res = spark.sql(\"SELECT * FROM mytable WHERE word1 = 'war' LIMIT 200\").collect()\n",
    "\n",
    "word_map1 = []\n",
    "for i in range(len(res)):\n",
    "    word_map1.append( ( res[i][1] , res[i][2] / spark.sql(\"SELECT count FROM table2 WHERE word = \"+\"'\"+res[i][1]+\"'\").collect()[0][0] ) )\n",
    "\n",
    "word_map1.sort(key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "be789e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('war', 1.4819277108433735),\n",
       " ('poll', 1.3333333333333333),\n",
       " ('neocon', 1.3333333333333333),\n",
       " ('resort', 1.1818181818181819),\n",
       " ('iraq', 1.1666666666666667),\n",
       " ('toss', 1.0909090909090908),\n",
       " ('drug', 1.0),\n",
       " ('fascist', 1.0),\n",
       " ('insist', 0.9333333333333333),\n",
       " ('cold', 0.9047619047619048),\n",
       " ('region', 0.8421052631578947),\n",
       " ('israel', 0.8),\n",
       " ('weapon', 0.7777777777777778),\n",
       " ('invasion', 0.7647058823529411),\n",
       " ('west', 0.7457627118644068),\n",
       " ('civilian', 0.7407407407407407),\n",
       " ('regime', 0.7391304347826086),\n",
       " ('christian', 0.6666666666666666),\n",
       " ('campaign', 0.6666666666666666),\n",
       " ('radical', 0.6470588235294118)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_map1[10:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "052fa3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('death', 0.2),\n",
       " ('office', 0.19047619047619047),\n",
       " ('action', 0.18292682926829268),\n",
       " ('s', 0.18055555555555555),\n",
       " ('population', 0.1724137931034483),\n",
       " ('world', 0.1717948717948718),\n",
       " ('bush', 0.17164179104477612),\n",
       " ('take', 0.16666666666666666),\n",
       " ('cause', 0.16352201257861634),\n",
       " ('kid', 0.16161616161616163),\n",
       " ('americans', 0.16049382716049382),\n",
       " ('figure', 0.16049382716049382),\n",
       " ('clear', 0.1595744680851064),\n",
       " ('provide', 0.15789473684210525),\n",
       " ('clearly', 0.15714285714285714),\n",
       " ('american', 0.1568627450980392),\n",
       " ('evil', 0.15584415584415584),\n",
       " ('freedom', 0.15384615384615385),\n",
       " ('private', 0.15294117647058825),\n",
       " ('crime', 0.1527777777777778)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_map1[80:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cee765d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('different', 0.0942622950819672),\n",
       " ('set', 0.09395973154362416),\n",
       " ('get', 0.09350649350649351),\n",
       " ('help', 0.09202453987730061),\n",
       " ('news', 0.09090909090909091),\n",
       " ('oh', 0.09022556390977443),\n",
       " ('kind', 0.09009009009009009),\n",
       " ('human', 0.08484848484848485),\n",
       " ('law', 0.08379888268156424),\n",
       " ('go', 0.08295964125560538),\n",
       " ('care', 0.08290155440414508),\n",
       " ('bad', 0.08123249299719888),\n",
       " ('hope', 0.08053691275167785),\n",
       " ('year', 0.07951807228915662),\n",
       " ('believe', 0.07861635220125786),\n",
       " ('know', 0.07587064676616916),\n",
       " ('true', 0.07425742574257425),\n",
       " ('pay', 0.07386363636363637),\n",
       " ('happen', 0.0735930735930736),\n",
       " ('tell', 0.07272727272727272)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_map1[130:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b05b937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ai\n",
    "\n",
    "res = spark.sql(\"SELECT * FROM mytable WHERE word1 = 'ai' LIMIT 200\").collect()\n",
    "\n",
    "word_map2 = []\n",
    "for i in range(len(res)):\n",
    "    word_map2.append( ( res[i][1] , res[i][2] / spark.sql(\"SELECT count FROM table2 WHERE word = \"+\"'\"+res[i][1]+\"'\").collect()[0][0] ) )\n",
    "\n",
    "word_map2.sort(key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7b0d982a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('redo', 1.0),\n",
       " ('opinionate', 0.6666666666666666),\n",
       " ('delay', 0.6666666666666666),\n",
       " ('atheism', 0.6),\n",
       " ('laziness', 0.5714285714285714),\n",
       " ('webserver', 0.5),\n",
       " ('cram', 0.5),\n",
       " ('ar', 0.5),\n",
       " ('starforce', 0.46153846153846156),\n",
       " ('shrink', 0.4444444444444444),\n",
       " ('supernatural', 0.42857142857142855),\n",
       " ('absence', 0.42857142857142855),\n",
       " ('dhh', 0.4),\n",
       " ('patience', 0.3333333333333333),\n",
       " ('mnemonicsloth', 0.3333333333333333),\n",
       " ('quirky', 0.3333333333333333),\n",
       " ('joelonsoftware', 0.2857142857142857),\n",
       " ('publisher', 0.26666666666666666),\n",
       " ('gp', 0.25),\n",
       " ('excel', 0.25)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_map2[15:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7b0f4995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('month', 0.039603960396039604),\n",
       " ('application', 0.0379746835443038),\n",
       " ('scientific', 0.03773584905660377),\n",
       " ('microsoft', 0.03773584905660377),\n",
       " ('joke', 0.037037037037037035),\n",
       " ('actual', 0.03636363636363636),\n",
       " ('brain', 0.03571428571428571),\n",
       " ('criticism', 0.034482758620689655),\n",
       " ('version', 0.03409090909090909),\n",
       " ('market', 0.03333333333333333),\n",
       " ('minute', 0.03333333333333333),\n",
       " ('concept', 0.030303030303030304),\n",
       " ('computer', 0.030120481927710843),\n",
       " ('edit', 0.028169014084507043),\n",
       " ('limit', 0.027777777777777776),\n",
       " ('piece', 0.027777777777777776),\n",
       " ('individual', 0.0273972602739726),\n",
       " ('hand', 0.027210884353741496),\n",
       " ('000', 0.02702702702702703),\n",
       " ('lot', 0.026829268292682926)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_map2[90:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2b2446e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('case', 0.013333333333333334),\n",
       " ('large', 0.013333333333333334),\n",
       " ('big', 0.012552301255230125),\n",
       " ('create', 0.0125),\n",
       " ('3', 0.012269938650306749),\n",
       " ('blog', 0.011976047904191617),\n",
       " ('pay', 0.011363636363636364),\n",
       " ('work', 0.0113314447592068),\n",
       " ('gt', 0.011220196353436185),\n",
       " ('get', 0.01038961038961039),\n",
       " ('care', 0.010362694300518135),\n",
       " ('talk', 0.009950248756218905),\n",
       " ('fact', 0.00974025974025974),\n",
       " ('real', 0.009615384615384616),\n",
       " ('agree', 0.009584664536741214),\n",
       " ('try', 0.009280742459396751),\n",
       " ('write', 0.009202453987730062),\n",
       " ('bad', 0.008403361344537815),\n",
       " ('different', 0.00819672131147541),\n",
       " ('see', 0.008)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_map2[150:170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0d1f882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# environment (we see words from both the nature-domain as well as the programming-domain)\n",
    "\n",
    "res = spark.sql(\"SELECT * FROM mytable WHERE word1 = 'environment' LIMIT 200\").collect()\n",
    "\n",
    "word_map3 = []\n",
    "for i in range(len(res)):\n",
    "    word_map3.append( ( res[i][1] , res[i][2] / spark.sql(\"SELECT count FROM table2 WHERE word = \"+\"'\"+res[i][1]+\"'\").collect()[0][0] ) )\n",
    "\n",
    "word_map3.sort(key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "67efde8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cm', 2.0),\n",
       " ('kernighan', 2.0),\n",
       " ('pike', 2.0),\n",
       " ('mutation', 0.8571428571428571),\n",
       " ('winter', 0.8),\n",
       " ('voltage', 0.75),\n",
       " ('gasoline', 0.6666666666666666),\n",
       " ('labs', 0.6666666666666666),\n",
       " ('electricity', 0.6153846153846154),\n",
       " ('mining', 0.6),\n",
       " ('sweden', 0.47058823529411764),\n",
       " ('xml', 0.4),\n",
       " ('plant', 0.38461538461538464),\n",
       " ('inequality', 0.375),\n",
       " ('organism', 0.375),\n",
       " ('led', 0.36363636363636365),\n",
       " ('solar', 0.3333333333333333),\n",
       " ('slowly', 0.3333333333333333),\n",
       " ('abandon', 0.3333333333333333),\n",
       " ('heat', 0.2727272727272727)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_map3[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d91fa20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hack', 0.11538461538461539),\n",
       " ('database', 0.1111111111111111),\n",
       " ('trade', 0.10810810810810811),\n",
       " ('library', 0.10526315789473684),\n",
       " ('scientist', 0.10416666666666667),\n",
       " ('aid', 0.10344827586206896),\n",
       " ('cs', 0.10256410256410256),\n",
       " ('maintain', 0.1),\n",
       " ('process', 0.09278350515463918),\n",
       " ('car', 0.0898876404494382),\n",
       " ('natural', 0.08928571428571429),\n",
       " ('influence', 0.08823529411764706),\n",
       " ('evolution', 0.08333333333333333),\n",
       " ('willing', 0.08163265306122448),\n",
       " ('java', 0.08108108108108109),\n",
       " ('behavior', 0.08108108108108109),\n",
       " ('waste', 0.08064516129032258),\n",
       " ('development', 0.08),\n",
       " ('press', 0.0784313725490196),\n",
       " ('design', 0.07407407407407407)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_map3[50:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "153e4cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mention', 0.04411764705882353),\n",
       " ('oil', 0.0423728813559322),\n",
       " ('e', 0.041666666666666664),\n",
       " ('main', 0.041666666666666664),\n",
       " ('fun', 0.04),\n",
       " ('level', 0.039603960396039604),\n",
       " ('solution', 0.03896103896103896),\n",
       " ('school', 0.038834951456310676),\n",
       " ('example', 0.038461538461538464),\n",
       " ('probably', 0.0379746835443038),\n",
       " ('internet', 0.037383177570093455),\n",
       " ('programming', 0.03669724770642202),\n",
       " ('population', 0.034482758620689655),\n",
       " ('subject', 0.034482758620689655),\n",
       " ('software', 0.03428571428571429),\n",
       " ('search', 0.03418803418803419),\n",
       " ('run', 0.03414634146341464),\n",
       " ('movie', 0.03409090909090909),\n",
       " ('paper', 0.03333333333333333),\n",
       " ('code', 0.03211009174311927)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_map3[90:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "24f23ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"serve-DataFrame\" java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.net.PlainSocketImpl.socketAccept(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:409)\n",
      "\tat java.net.ServerSocket.implAccept(ServerSocket.java:560)\n",
      "\tat java.net.ServerSocket.accept(ServerSocket.java:528)\n",
      "\tat org.apache.spark.security.SocketAuthServer$$anon$1.run(SocketAuthServer.scala:64)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#knife\n",
    "\n",
    "res = spark.sql(\"SELECT * FROM mytable WHERE word1 = 'knife' LIMIT 200\").collect()\n",
    "\n",
    "word_map3 = []\n",
    "for i in range(len(res)):\n",
    "    word_map3.append( ( res[i][1] , res[i][2] / spark.sql(\"SELECT count FROM table2 WHERE word = \"+\"'\"+res[i][1]+\"'\").collect()[0][0] ) )\n",
    "\n",
    "word_map3.sort(key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d97534f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('butcher', 1.0),\n",
       " ('nefarious', 1.0),\n",
       " ('lamb', 0.5),\n",
       " ('meantime', 0.2),\n",
       " ('divide', 0.16666666666666666),\n",
       " ('neighbor', 0.14285714285714285),\n",
       " ('slavery', 0.14285714285714285),\n",
       " ('acceptance', 0.14285714285714285),\n",
       " ('confidence', 0.14285714285714285),\n",
       " ('ponder', 0.125),\n",
       " ('convinced', 0.125),\n",
       " ('worse', 0.125),\n",
       " ('objection', 0.125),\n",
       " ('conquer', 0.1111111111111111),\n",
       " ('slaughter', 0.1111111111111111),\n",
       " ('enable', 0.09523809523809523),\n",
       " ('manipulate', 0.08333333333333333),\n",
       " ('politician', 0.07142857142857142),\n",
       " ('safety', 0.06896551724137931),\n",
       " ('ignore', 0.05660377358490566)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_map3[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "326f7d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lack', 0.030303030303030304),\n",
       " ('factor', 0.02702702702702703),\n",
       " ('handle', 0.02631578947368421),\n",
       " ('definitely', 0.023255813953488372),\n",
       " ('discuss', 0.02040816326530612),\n",
       " ('faith', 0.018867924528301886),\n",
       " ('net', 0.016666666666666666),\n",
       " ('average', 0.015625),\n",
       " ('freedom', 0.015384615384615385),\n",
       " ('accept', 0.015384615384615385),\n",
       " ('past', 0.014925373134328358),\n",
       " ('social', 0.014492753623188406),\n",
       " ('main', 0.013888888888888888),\n",
       " ('personal', 0.012345679012345678),\n",
       " ('self', 0.010526315789473684),\n",
       " ('deal', 0.01020408163265306),\n",
       " ('useful', 0.009433962264150943),\n",
       " ('thank', 0.008695652173913044),\n",
       " ('effect', 0.008620689655172414),\n",
       " ('lead', 0.008333333333333333)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_map3[25:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "06be6ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('easy', 0.005681818181818182),\n",
       " ('pay', 0.005681818181818182),\n",
       " ('end', 0.005376344086021506),\n",
       " ('person', 0.005076142131979695),\n",
       " ('money', 0.005050505050505051),\n",
       " ('kind', 0.0045045045045045045),\n",
       " ('go', 0.004484304932735426),\n",
       " ('guy', 0.0033333333333333335),\n",
       " ('agree', 0.003194888178913738),\n",
       " ('get', 0.0025974025974025974),\n",
       " ('make', 0.002398081534772182),\n",
       " ('well', 0.0020833333333333333),\n",
       " ('want', 0.001692047377326565),\n",
       " ('think', 0.001451378809869376),\n",
       " ('like', 0.0013297872340425532),\n",
       " ('good', 0.001072961373390558),\n",
       " ('people', 0.0006381620931716656)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_map3[50:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f28211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ranges of the neighbors are adjusted so that they fit better to each word.\n",
    "# We see that some words work better than others. The map that we created is far from being perfect, it contains many cases\n",
    "# of \"words\" with no meaning, or misspelled words. (This can happen if a big comment contains many times the \"central\" word\n",
    "# and 1 time a misspelled word. This increases the \"recall\" of the misspelled word and it tends to be selected and positioned\n",
    "# higher)\n",
    "# \n",
    "# However it was very interesting to see that we can have a partially working result with elementary methods !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e80ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
